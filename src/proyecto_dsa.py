# -*- coding: utf-8 -*-
"""Proyecto_DSA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12G3uvw2kN-vF1D9mb7Ayl12gAbWu0oEH

# Proyecto_DSA

**SEGMENTACIÓN DE USUARIOS PARA MEJORA DE EXPERIENCIA EN SITIOS WEB DE COMERCIO ELECTRÓNICO**

#### **Contexto del proyecto**

El comercio electrónico se ha vuelto esencial para las empresas en la era de internet y la globalización, pero comprender y mejorar la retención de clientes en las páginas web es un desafío complejo. Este proyecto busca construir un modelo de clustering no supervisado para segmentar a los usuarios en grupos basados en su comportamiento en el sitio web. El objetivo no es predecir ventas, sino identificar los factores que llevan a los usuarios a abandonar el proceso de compra. Se utilizarán modelos como DBSCAN, K-medias y K-medoides para agrupar a los usuarios y analizar dónde se detienen en el embudo de conversión. Estos grupos servirán como insumo para optimizar estrategias de marketing y retención de clientes, permitiendo a los especialistas del comercio electrónico identificar características clave. Aunque se considera DBSCAN debido a sus ventajas, se realizarán comparaciones con otros métodos de clustering para tomar una decisión informada. El proyecto busca responder a la pregunta de cómo identificar los factores principales que afectan el abandono de usuarios en el proceso de compra y, así, mejorar las estrategias de mercadeo y retención.

# Desarrollo

### 1. Carga de datos

En la carpeta `data` se encuentra el archivo `online_shoppers_intention.csv` cargue estos datos en su *cuaderno*.
"""

# Importamos las librerias que vamos a utilizar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#Cargamos los datos
df = pd.read_csv('data/online_shoppers_intention.csv', sep=',')
df.head()

# Ver datos unicos de la columna Month
df['Month'].unique()

# Reemplazamos nuestras variables dummies con 0 y 1
df.Weekend = df.Weekend.replace({True: 1, False: 0})
df.Revenue = df.Revenue.replace({True: 1, False: 0})

df.Month = df.Month.replace({'Feb': 2, 'Mar': 3, 'May': 5, 'June': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov':11, 'Dec': 12})

df

# Tenemos variables categoricas, por lo cual debemos crear la dummies correspondientes
cat_cols = ['VisitorType']
dummies = pd.get_dummies(df[cat_cols], prefix=cat_cols)

# Concatenamos los datos originales con las variables ficticias
df_con_dummies = pd.concat([df, dummies], axis=1)

# Eliminamos las variables originales ya que ahora tenemos las variables ficticias
df_con_dummies = df_con_dummies.drop(cat_cols, axis=1)

# Imprimimos el dataframe con las variables ficticias
df_con_dummies.head()

# Validamos que no se tengan valores nulos
nulos = df.isnull().sum()
print('Cantidad de nulos en la data:',nulos.sum())

#Obtenemos el tamaño de los datos
df.shape

"""Importamos pandas y cargamos los datos del csv. Usamos la funcion head para tener una primera visualizacion de los datos cargados

###**Descripción de los datos**

Se van a utilizar los datos “Online Shoppers Purchasing Intention Dataset” [https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset]. Estos están compuestos por 12.330 registros y 18 variables. Las variables son las siguientes:

Administrative: Indica el número de páginas de la categoría Administrativa visitadas en la sesión.

Administrative_Duration: Indica la duración en segundos en páginas Administrativas durante la sesión.

Informational: Indica el número de páginas de la categoría Informativa visitadas en la sesión.

Informational_Duration: Indica la duración en segundos en páginas informativas durante la sesión.

ProductRelated: Indica el número de páginas de la categoría Productos visitadas en la sesión.

ProductRelated_Duration: Indica la duración en segundos en páginas de productos durante la sesión.

BounceRates: Métrica construida por Google Analytics, indica la tasa de rebote de la página visitada (rebote se refiere a que la persona sale de la sesión visitando sólo una página).

ExitRates: Métrica construida por Google Analytics, indica la tasa de salida de la última página visitada.

PageValues: Métrica construida por Google Analytics, indica el valor promedio de la última página visitada (Para que una página tenga valor, se debió presentar una compra alguna sesión).

SpecialDay: Indica que tan cerca estaba la visita con respecto a alguna fecha festiva. 1 indica que la visita fue hecha el mismo día de la festividad, 0 si no se encuentra cerca.

Month: Mes de la visita.

OperatingSystems: Id del sistema operativo.

Browser: Id del browser usado.

Region: Id de la región del usuario realizando la visita.

TrafficType: Tipo de tráfico.

Visitor_Type: Returning en caso de usuario recurrente, new en caso de usuario nuevo.

Weekend: Indica si la visita fue durante un fin de semana.

Revenue: Indica si se realizó alguna compra durante la visita en cuestión.

### 2.  Análisis descriptivo de las variables.

Para el análisis descriptivo utilizamos de estadísticas descriptivas y matrices de correlación.
"""

# Creamos un data frame con estadísticas descriptivas para cada columna
df_descriptive_stats = df_con_dummies.describe()

# mostramos el data frame
df_descriptive_stats

# Continuamos revisando la cantidad de visitas online que fueron efectivas

# Creamos el plot
sns.set(style="whitegrid")
plt.figure(figsize=(8, 6))
ax = sns.countplot(data=df, x='Revenue', palette='Set2')

# Organizamos el titulo y el nombre del eje x y y
plt.title('Total Revenue', fontsize=15)
plt.xlabel('Revenue completado', fontsize=12)
plt.ylabel('Cantidad', fontsize=12)

# Añadimos los % de las visitas efectivas
total_count = len(df)
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height() / total_count)
    x = p.get_x() + p.get_width() / 2
    y = p.get_height()
    ax.annotate(percentage, (x, y), ha='center', va='bottom', fontsize=12)

plt.show()

"""En la grafica podemos ver que en el total de visitas, el 84% no termino en compra mientras que el 16% si fue efectivo."""

# Variables numericas
val_num = df_con_dummies.select_dtypes(include=["number"])

# Calculamos la matriz de correlacion
correlation_matrix = val_num.corr()
correlation_matrix

# Creamos un mapa de calor
plt.figure(figsize=(30, 30))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix Heatmap')
plt.show()

"""
Vemos que la correlación más fuerte de Revenue es con PageValues"""

# Construimos el histograma
hist = val_num.hist(bins = 'auto', figsize=(20,20))






"""##### Pasos
- Se realiza la importación de los datos
- Se verifican datos nulos
- Se convierten las variables categóricas a variables dummy
- Se crea un gráfico de la variable Revenue para ver cuantas de las visitas son efectivas
- Se obtuvieron las estadísticas descriptivas de todas las variables
- Se genera el gráfico de correlación
- Se genera histograma de la variable de interés

#### Procedimiento
Primero, realizamos un proceso de limpieza de datos en donde verificamos los valores nulos. Luego, transformamos las variables de Revenue y Weekend que originalmente tenían valores 'true' y 'false' en valores numéricos, asignando 1 y 0. Continuando, convertimos las variables de categóricas a variables dummies y obtuvimos las estadísticas descriptivas de cada una de las variables. En las estadísticas descriptivas podemos observar que por sesión los usuarios entran en promedio a 2 páginas administrativas, la mitad de ellos visitó por lo menos 18 páginas relacionadas a productos y las tasas máximas de rebote y salida que tenemos en alguna(s) pagina(s) es 20%.

#### Resumen Análisis Descriptivo
De acuerdo con los resultados, podemos observar que la distribución de los datos con respecto a las visitas realizadas en el sitio web y la duración en las diferentes secciones, así como también la concurrencia para los diferentes meses. Para la variable Exit Rate vemos que las personas que navegan por el sitio tienen tendencia a estar poco tiempo; para la variable Browser se ve la preferencia de uso de un navegador especifico para acceder al sitio, como también que una de las regiones tiene mayor concentración de datos.


"""

"""# Seleccionamos las variables de Page Values, bounce rates y exits rates para comparar con box plot"""
selected_vars = ['PageValues', 'BounceRates', 'ExitRates']

"""# Boxplot para pagevalues, bounce rates y exit rates en función de Revenue"""
plt.figure(figsize=(14, 8))
for i, col in enumerate(selected_vars):
    plt.subplot(1, 3, i + 1)
    sns.boxplot(x='Revenue', y=col, data=df_con_dummies, palette='Set2')
    plt.title(f'Boxplot para {col}')
#Mostramos el graficto
plt.tight_layout()
plt.show()

"""# obtenemos las estadisticas descriptivas"""
desc_stats = df_con_dummies.groupby('Revenue')[selected_vars].describe()
print("Estadisticas Descriptivas:")
print(desc_stats)

"""##Con el boxplot podemos ver que las visitas que no generan revenue tienen una tasa de rebote mucho más alta en comparación con las que si. La media es de 0.0253 mientras que las que sí generan revenue tiene una media de 0.00051, mostrando una tasa de rebote significativamente baja. De esto se puede concluir que las visitas que, si generan ingresos a la empresa, tienen menos probabilidad de tener un alto porcentaje de bounce rates."""
